# -*- coding: utf-8 -*-
"""ConvNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10u1AA5cuYnAvAWkweUKm4jdrWInkEAeO
"""

import numpy as np
import torch
import matplotlib.pyplot as plt
import torchvision as tv

B = 50

transf = tv.transforms.Compose(
    [tv.transforms.ToTensor(),
     tv.transforms.Normalize([0.5],[0.5],[0.5])])   ### transforma los datos de [0,1] a [-1,1]

trn_data = tv.datasets.CIFAR10(root='./data', train=True, download=True, transform=tv.transforms.ToTensor())
tst_data = tv.datasets.CIFAR10(root='./data', train=False, download=True, transform=tv.transforms.ToTensor())

trn_load = torch.utils.data.DataLoader(dataset=trn_data, batch_size=B, shuffle=True)
tst_load = torch.utils.data.DataLoader(dataset=tst_data, batch_size=B, shuffle=True)

class ConvNet(torch.nn.Module):

  def __init__(self, clases):
    super().__init__()
    self.c1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2, padding=2)
    self.c2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
    self.MP = torch.nn.MaxPool2d(kernel_size=2, stride=2)
    self.H = 32 * 8 * 8
    self.O = 512
    self.L1 = torch.nn.Linear(self.H, self.O)
    self.L2 = torch.nn.Linear(self.O,clases)

  def forward(self, image):
    o1 = self.c1(image).relu()
    o2 = self.c2(o1)    
    o3 = self.MP(o2).relu()
    o4 = self.L1(o3.view(-1,self.H)).tanh()
    return self.L2(o4)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

idata = iter(tst_load)
image, label = next(idata)

model = ConvNet(10)
optim = torch.optim.Adam(model.parameters())
costf = torch.nn.CrossEntropyLoss()

T = 10

for t in range(T):
  E = 0
  for image, label in trn_load:
    optim.zero_grad()
    y = model(image)
    error = costf(y, label)
    error.backward()
    optim.step()
    E += error.item()
  print(t, E)

model.eval()
#  right, total = 0, 0
#  with torch.no_grad():
#      for images, labels in tst_load:
#          y = model(images)
#          right += (y.argmax(dim=1)==labels).sum().item()
#          total += len(labels)
#
#  accuracy = right / total
#  print('Precisi√≥n: ', accuracy)

"""
puedo usar la red convolucional para hacer un autoencoder

_.enc = torch.nn.Sequential(
  conv2d(...),
  torch.nn.ReLU(True))

_.dec = torch.nn.ConvTranspose2d()
Tanh()
"""